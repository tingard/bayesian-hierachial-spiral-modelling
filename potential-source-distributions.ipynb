{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential source distributions\n",
    "\n",
    "[Pringle & Dobbs (2019)](https://arxiv.org/pdf/1909.10291.pdf) propose that for a simple model of spiral awm winding, galaxy pitch angle should be uniform in $\\cot\\phi$ between some limits. We examine this possibility using repetitions of the [Kolmogorov-Smirnov](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test) and [Anderson-Darling](https://en.wikipedia.org/wiki/Anderson%E2%80%93Darling_test) tests for different realizations of the posterior distribution of galaxy pitch angle (which we will refer to as _marginalized tests_). We also invsetigate the Beta distribution and Truncated Normal distribution as possible source distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.text import Annotation\n",
    "from matplotlib import rc\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize\n",
    "import pymc3 as pm\n",
    "from tqdm import tqdm\n",
    "import scipy.stats as st\n",
    "import corner\n",
    "import warnings\n",
    "from IPython.display import Latex\n",
    "from gzbuilder_analysis import load_fit_results\n",
    "\n",
    "warnings.simplefilter('ignore', UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    }
   ],
   "source": [
    "fit_results = load_fit_results('../gzbuilder_results/output_files/tuning_results', ext='pickle.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    294.000000\n",
       "mean       1.589997\n",
       "std        0.765085\n",
       "min        1.012060\n",
       "25%        1.153419\n",
       "50%        1.337545\n",
       "75%        1.824268\n",
       "max        8.493264\n",
       "Name: chisq, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_results.chisq.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false,
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "INPUT_FILE = 'n139d1000t500.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "res = pd.read_pickle(INPUT_FILE)\n",
    "bhsm = res['model']\n",
    "trace = res['trace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "            \\begin{array}{rcl}\n",
       "            \\text{c} &\\sim & \\text{Cauchy}(\\mathit{alpha}=0.0,~\\mathit{beta}=10.0)\\\\\\text{phi_gal} &\\sim & \\text{Uniform}(\\mathit{lower}=0.0,~\\mathit{upper}=90.0)\\\\\\text{sigma_gal} &\\sim & \\text{InverseGamma}(\\mathit{alpha}=2.0,~\\mathit{beta}=20.0)\\\\\\text{sigma_r} &\\sim & \\text{InverseGamma}(\\mathit{alpha}=2.0,~\\mathit{beta}=0.5)\\\\\\text{phi_arm} &\\sim & \\text{TruncatedNormal}(\\mathit{mu}=f(\\text{phi_gal},~array),~\\mathit{sigma}=f(\\text{sigma_gal}),a=0.0,b=90.0)\\\\\\text{Likelihood} &\\sim & \\text{Normal}(\\mathit{mu}=f(f(f(f(f(f(f(),~\\text{phi_arm})),~array),~array),~f(\\text{c},~array))),~\\mathit{sigma}=f(\\text{sigma_r}))\n",
       "            \\end{array}\n",
       "            $$"
      ],
      "text/plain": [
       "<pymc3.model.Model at 0x1a28141e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(bhsm.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "def cot(phi):\n",
    "    return 1 / np.tan(np.radians(phi))\n",
    "\n",
    "def acot(a):\n",
    "    return np.degrees(np.arctan(1 / a))\n",
    "\n",
    "def truncnorm(loc, scale, lower=0, upper=90):\n",
    "    return st.truncnorm(\n",
    "        (lower - loc) / scale, (upper - loc) / scale,\n",
    "        loc=loc, scale=scale\n",
    "    )\n",
    "\n",
    "def truncnorm_nnlf(loc, scale, data, lower=0, upper=90):\n",
    "    a, b = (lower - loc) / scale, (upper - loc) / scale\n",
    "    return st.truncnorm.nnlf((a, b, loc, scale), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "## Limits from Pringle and Dobbs\n",
    "# LOWER_COT_BOUND = 1.0\n",
    "# UPPER_COT_BOUND = 4.75\n",
    "\n",
    "# lower_phi_bound = acot(UPPER_COT_BOUND)\n",
    "# upper_phi_bound = acot(LOWER_COT_BOUND)\n",
    "# print(f'{LOWER_COT_BOUND:.2f} < cot(ɸ) < {UPPER_COT_BOUND:.2f}')\n",
    "# print(f'{lower_phi_bound:.2f} < ɸ < {upper_phi_bound:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using the limits from Pringle & Dobbs, we adjust our bounds slightly to reflect our different method of pitch angle determination (determined by eye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$0.84 < \\cot(\\phi) < 3.73$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$15.00 < \\phi < 15.00$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LOWER_COT_BOUND = cot(50)\n",
    "UPPER_COT_BOUND = cot(15)\n",
    "\n",
    "lower_phi_bound = acot(UPPER_COT_BOUND)\n",
    "upper_phi_bound = acot(LOWER_COT_BOUND)\n",
    "\n",
    "display(Latex(r'${:.2f} < \\cot(\\phi) < {:.2f}$'.format(LOWER_COT_BOUND, UPPER_COT_BOUND)))\n",
    "display(Latex(r'${:.2f} < \\phi < {:.2f}$'.format(lower_phi_bound, lower_phi_bound)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also test against a lower value of $\\phi_\\mathrm{min}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$0.84 < \\cot(\\phi) < 5.67$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$10.00 < \\phi < 10.00$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LOWER_COT_BOUND2 = cot(50)\n",
    "UPPER_COT_BOUND2 = cot(10)\n",
    "\n",
    "lower_phi_bound2 = acot(UPPER_COT_BOUND2)\n",
    "upper_phi_bound2 = acot(LOWER_COT_BOUND2)\n",
    "\n",
    "display(Latex(r'${:.2f} < \\cot(\\phi) < {:.2f}$'.format(LOWER_COT_BOUND2, UPPER_COT_BOUND2)))\n",
    "display(Latex(r'${:.2f} < \\phi < {:.2f}$'.format(lower_phi_bound2, lower_phi_bound2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the _Marginalized_ tests for the different distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputExpanded": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1240/2000 [01:50<01:45,  7.22it/s]"
     ]
    }
   ],
   "source": [
    "# Test against cot-uniform\n",
    "ks = pd.Series([], name='ks_test_result', dtype=object)\n",
    "anderson = pd.Series([], name='anderson_test_result', dtype=object)\n",
    "cot_target_dist = st.uniform(LOWER_COT_BOUND, UPPER_COT_BOUND - LOWER_COT_BOUND)\n",
    "comparison_dataset = cot_target_dist.rvs(10000)\n",
    "\n",
    "# Test against cot-uniform with adjusted limits\n",
    "ks2 = pd.Series([], name='ks_test_result2', dtype=object)\n",
    "anderson2 = pd.Series([], name='anderson_test_result2', dtype=object)\n",
    "cot_target_dist2 = st.uniform(LOWER_COT_BOUND2, UPPER_COT_BOUND2 - LOWER_COT_BOUND2)\n",
    "comparison_dataset2 = cot_target_dist2.rvs(10000)\n",
    "\n",
    "\n",
    "# Test against scaled beta\n",
    "ks_beta = pd.Series([], name='ks_test_result', dtype=object)\n",
    "anderson_beta = pd.Series([], name='anderson_test_result', dtype=object)\n",
    "betas = []\n",
    "\n",
    "# Test against truncated normal\n",
    "ks_truncnorm = pd.Series([], name='ks_test_result', dtype=object)\n",
    "anderson_truncnorm = pd.Series([], name='anderson_test_result', dtype=object)\n",
    "truncnorms = []\n",
    "\n",
    "with tqdm(range(trace['phi_gal'].shape[0])) as bar:\n",
    "    for i in bar:\n",
    "        phi_gal_est = trace['phi_gal'][i]\n",
    "        cot_phi_gal_est = cot(phi_gal_est)\n",
    "        \n",
    "        cot_mask = (cot_phi_gal_est > LOWER_COT_BOUND) & (cot_phi_gal_est < UPPER_COT_BOUND)\n",
    "        anderson[i] = st.anderson_ksamp((\n",
    "            cot_phi_gal_est[cot_mask],\n",
    "            comparison_dataset,\n",
    "        ))\n",
    "        ks[i] = st.kstest(\n",
    "            cot_phi_gal_est[cot_mask],\n",
    "            cot_target_dist.cdf,\n",
    "        )\n",
    "        \n",
    "        cot_mask2 = (cot_phi_gal_est > LOWER_COT_BOUND2) & (cot_phi_gal_est < UPPER_COT_BOUND2)\n",
    "        anderson2[i] = st.anderson_ksamp((\n",
    "            cot_phi_gal_est[cot_mask2],\n",
    "            comparison_dataset2,\n",
    "        ))\n",
    "        ks2[i] = st.kstest(\n",
    "            cot_phi_gal_est[cot_mask2],\n",
    "            cot_target_dist2.cdf,\n",
    "        )\n",
    "        \n",
    "        beta_fit = st.beta(*st.beta.fit(phi_gal_est, fscale=90, floc=0))\n",
    "        betas.append(beta_fit)\n",
    "        truncnorm_fit = truncnorm(\n",
    "            *minimize(lambda p: truncnorm_nnlf(*p, phi_gal_est), (10, 10))['x']\n",
    "        )\n",
    "        truncnorms.append(truncnorm_fit)\n",
    "\n",
    "ks = ks.apply(pd.Series).rename(columns={0: 'value', 1: 'p'})\n",
    "anderson = anderson.apply(pd.Series).rename(columns={0: 'value', 1: 'levels', 2: 'significance'})\n",
    "\n",
    "ks2 = ks2.apply(pd.Series).rename(columns={0: 'value', 1: 'p'})\n",
    "anderson2 = anderson2.apply(pd.Series).rename(columns={0: 'value', 1: 'levels', 2: 'significance'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cheeky helper function to do custom logarithmic histogramming:\n",
    "\n",
    "**Logarithmic Histogramming is often disingenuous, so should be interpreted _very_ carfully**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "def do_log_hist(vals, *args, **kwargs):\n",
    "    cumulative = kwargs.pop('cumulative', False)\n",
    "    counts, bins = np.histogram(np.log10(vals), bins='scott', *args, **kwargs)\n",
    "    if cumulative:\n",
    "        counts = np.cumsum(counts / counts.sum())\n",
    "    line = plt.step(10**bins, np.concatenate(([0], counts)), color='C1')[0]\n",
    "    plt.fill_between(10**np.repeat(bins, 2)[1:-1], np.repeat(counts, 2), color='C1', alpha=0.2)\n",
    "    plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputExpanded": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=1, figsize=(12, 3), dpi=100)\n",
    "# plt.sca(ax[0])\n",
    "plt.title('Anderson-Darling test results for posterior samples')\n",
    "sns.kdeplot(anderson['value'], label='', shade=True)\n",
    "print('Thresholds:')\n",
    "for i, j in zip(\n",
    "    ('25%', '10%', '5%', '2.5%', '1%', '0.5%', '0.1%'),\n",
    "    np.stack(anderson['levels'].values).mean(axis=0)\n",
    "):\n",
    "    freq = (anderson['value'] >= j).sum() / len(anderson['value'])\n",
    "    print(f'{i: >10}: {j:.2f}, reject {freq:.0%} of the time')\n",
    "    plt.axvline(j, color='k', alpha=0.2)\n",
    "    plt.text(j, plt.ylim()[1]*0.9, i)\n",
    "plt.xlabel('Anderson-Darling statistic')\n",
    "\n",
    "# # Plot log-hist of KS probabilities\n",
    "# plt.sca(ax[1])\n",
    "# plt.title(r'Kolmogorov–Smirnov test results for posterior samples')\n",
    "# do_log_hist(ks['p'])\n",
    "# plt.xlim(left=1E0, right=plt.xlim()[0])\n",
    "# plt.xlabel(r'Probability of phi being uniform in cot')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('plots/cot_uniform_marginalized_tests.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore we cannot unilaterally reject the hypothesis that the galaxy pitch angles for our sample are uniformly distributed in $\\cot$ between the limits present in [Pringle & Dobbs (2019)](https://arxiv.org/pdf/1909.10291.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**However**, adjusting the limits to be between 10° and 40° provides a strong rejection of the null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=1, figsize=(12, 3), dpi=100)\n",
    "\n",
    "# plt.sca(ax[0])\n",
    "plt.title('Anderson-Darling test results for posterior samples')\n",
    "sns.kdeplot(anderson2['value'], label='', shade=True)\n",
    "print('Thresholds (adjusted limits):')\n",
    "for i, j in zip(\n",
    "    ('25%', '10%', '5%', '2.5%', '1%', '0.5%', '0.1%'),\n",
    "    np.stack(anderson2['levels'].values).mean(axis=0)\n",
    "):\n",
    "    freq = (anderson2['value'] >= j).sum() / len(anderson2['value'])\n",
    "    print(f'{i: >10}: {j:.2f}, reject {freq:.0%} of the time')\n",
    "    plt.axvline(j, color='k', alpha=0.2)\n",
    "    plt.text(j, plt.ylim()[1]*0.9, i)\n",
    "plt.xlabel('Anderson-Darling statistic')\n",
    "\n",
    "# # Plot log-hist of KS probabilities\n",
    "# plt.sca(ax[1])\n",
    "# plt.title(r'Kolmogorov–Smirnov test results for posterior samples')\n",
    "# do_log_hist(ks2['p'])\n",
    "# plt.xlim(left=1E0, right=plt.xlim()[0])\n",
    "# plt.xlabel(r'Probability of phi being uniform in cot')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the observed pitch angles could definitely be drawn from a Beta distribution like\n",
    "\n",
    "$$\\phi_\\mathrm{gal} \\sim 90 \\times \\mathrm{Beta}(a,\\ b)$$\n",
    "\n",
    "A normal distribution truncated between 0 and 90 is also a good candidate.\n",
    "\n",
    "$$\\phi_\\mathrm{gal} \\sim \\mathrm{TruncatedNormal}(\\mu,\\ \\sigma,\\ \\mathrm{lower}=0,\\ \\mathrm{upper}=90)$$\n",
    "\n",
    "We illustrate the different potential source distributions using their fitted values for each draw (apart from the cot-uniform, which for convenience is a histogram of points sampled from the distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "_x = np.linspace(0, 90, 1000)\n",
    "truncnorm_evals = np.array([t.pdf(_x) for t in truncnorms])\n",
    "beta_evals = np.array([b.pdf(_x) for b in betas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": true,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "sf = len(gal_pa_samples.unstack().where(lambda a: (a > lower_phi_bound)&(a < upper_phi_bound)).dropna()) / gal_pa_samples.size\n",
    "\n",
    "_x = np.linspace(0, 90, 1000)\n",
    "plt.figure(figsize=(12, 6), dpi=100)\n",
    "cot_counts, cot_bins = np.histogram(acot(comparison_dataset), density=True, bins='scott')\n",
    "ct_l = plt.step(\n",
    "    np.concatenate(([0], cot_bins, [90])),\n",
    "    np.concatenate(([0, 0], cot_counts, [0])) * sf,\n",
    "    color='C0', label='Phi uniform in cot', lw=3\n",
    ")\n",
    "tn_mns = truncnorm_evals.mean(axis=0)\n",
    "tn_stds = truncnorm_evals.std(axis=0)\n",
    "tn_l = plt.plot(_x, tn_mns, c='C1', lw=3, label='Combined Truncated normal fits')\n",
    "plt.fill_between(\n",
    "    _x,\n",
    "    tn_mns - tn_stds,\n",
    "    tn_mns + tn_stds,\n",
    "    color='C1', alpha=0.3\n",
    ")\n",
    "bt_l = plt.plot(_x, beta_evals.mean(axis=0), c='C2', lw=3, label='Combined Scaled Beta fits')\n",
    "bt_mns = beta_evals.mean(axis=0)\n",
    "bt_stds = beta_evals.std(axis=0)\n",
    "plt.fill_between(\n",
    "    _x,\n",
    "    bt_mns - bt_stds,\n",
    "    bt_mns + bt_stds,\n",
    "    color='C2', alpha=0.4\n",
    ")\n",
    "\n",
    "# plot a histogram with errors of the posterior realizations used to fit things\n",
    "counts, bins = np.histogram(gal_pa_samples.T.iloc[0], bins='auto', density=True)\n",
    "\n",
    "res = pd.DataFrame([], columns=np.concatenate((bins[:-1] + np.diff(bins) / 2, (90,))), index=gal_pa_samples.index)\n",
    "for idx, val in gal_pa_samples.iteritems():\n",
    "    counts, _ = np.histogram(val, bins=bins, density=True)\n",
    "    res.loc[idx] = pd.Series(counts, index=bins[:-1] + np.diff(bins) / 2)\n",
    "\n",
    "l_data = plt.errorbar(\n",
    "    res.columns, res.mean(), yerr=res.std(),\n",
    "    fmt='.', color='k',\n",
    "    label='Histogrammed galaxy pitch angle predictions',\n",
    "    zorder=3, capsize=2\n",
    ")\n",
    "\n",
    "plt.plot(np.concatenate((np.repeat(bins, 2), (90,))), np.concatenate(([0], np.repeat(res.mean(), 2).values)), c='k')\n",
    "plt.legend()\n",
    "plt.xlabel(r'Pitch angle, $\\phi_\\mathrm{gal}$')\n",
    "plt.yticks([]);\n",
    "plt.savefig('plots/distribution_comparison.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about on an arm-by-arm basis?\n",
    "\n",
    "If arms form and wind independently of each other, we would expect arm pitch angle to be uniformly distributed in cot, and not (necessarily) the pitch angle of a galaxy as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOWER_COT_BOUND_ARM = LOWER_COT_BOUND  # = cot(50)\n",
    "UPPER_COT_BOUND_ARM = UPPER_COT_BOUND  # = cot(15)\n",
    "\n",
    "lower_phi_bound_arm = acot(UPPER_COT_BOUND_ARM)\n",
    "upper_phi_bound_arm = acot(LOWER_COT_BOUND_ARM)\n",
    "print(f'{LOWER_COT_BOUND_ARM:.2f} < cot(ɸ) < {UPPER_COT_BOUND_ARM:.2f}')\n",
    "print(f'{lower_phi_bound_arm:.2f} < ɸ < {upper_phi_bound_arm:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test against cot-uniform\n",
    "ks_arm = pd.Series([], name='ks_test_result', dtype=object)\n",
    "anderson_arm = pd.Series([], name='anderson_test_result', dtype=object)\n",
    "arm_cot_target_dist = st.uniform(LOWER_COT_BOUND_ARM, UPPER_COT_BOUND_ARM - LOWER_COT_BOUND_ARM)\n",
    "arm_comparison_dataset = arm_cot_target_dist.rvs(10000)\n",
    "\n",
    "with tqdm(range(trace['phi_arm'].shape[0])) as bar:\n",
    "    for i in bar:\n",
    "        phi_arm_est = trace['phi_arm'][i]\n",
    "        cot_phi_arm_est = cot(phi_arm_est)\n",
    "        cot_mask = (cot_phi_arm_est > LOWER_COT_BOUND_ARM) & (cot_phi_arm_est < UPPER_COT_BOUND_ARM)\n",
    "        anderson_arm[i] = st.anderson_ksamp((\n",
    "            cot_phi_arm_est[cot_mask],\n",
    "            arm_comparison_dataset,\n",
    "        ))\n",
    "        ks_arm[i] = st.kstest(\n",
    "            cot_phi_arm_est[cot_mask],\n",
    "            arm_cot_target_dist.cdf,\n",
    "        )\n",
    "\n",
    "ks_arm = ks_arm.apply(pd.Series).rename(columns={0: 'value', 1: 'p'})\n",
    "anderson_arm = anderson_arm.apply(pd.Series).rename(columns={0: 'value', 1: 'levels', 2: 'significance'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejection_frac = pd.Series([\n",
    "    (anderson_arm['value'] >= j).sum() / len(anderson['value'])\n",
    "    for j in np.stack(anderson_arm['levels'].values).mean(axis=0)\n",
    "], index=('25%', '10%', '5%', '2.5%', '1%', '0.5%', '0.1%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=1, figsize=(12, 3), dpi=100)\n",
    "# plt.sca(ax[0])\n",
    "sns.kdeplot(anderson_arm['value'], label='', shade=True)\n",
    "print('Thresholds:')\n",
    "for i, j in zip(\n",
    "    ('25%', '10%', '5%', '2.5%', '1%', '0.5%', '0.1%'),\n",
    "    np.stack(anderson_arm['levels'].values).mean(axis=0)\n",
    "):\n",
    "    print(f'{i: >10}: {j:.2f}, reject {rejection_frac.loc[i]:.0%} of the time')\n",
    "    plt.axvline(j, color='k', alpha=0.2)\n",
    "    plt.text(j, plt.ylim()[1]*0.9, i)\n",
    "plt.xlabel('Anderson-Darling statistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also plot the resulting fit, scaling the histogram such that the histograms match (densities within bounds add up to one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_gal = len(gal_pa_samples.T.where(lambda a: (a > lower_phi_bound_arm)&(a < upper_phi_bound_arm)).unstack().dropna()) / gal_pa_samples.size\n",
    "sf_arm = len(arm_pa_samples.T.where(lambda a: (a > lower_phi_bound_arm)&(a < upper_phi_bound_arm)).unstack().dropna()) / arm_pa_samples.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_hist(samples):\n",
    "    # Each row is a sample, each column is a pitch angle\n",
    "    counts, bins = np.histogram(\n",
    "        samples.mean(axis=0),\n",
    "        bins='scott', density=True\n",
    "    )\n",
    "    cols = bins[:-1] + np.diff(bins) / 2\n",
    "    res = pd.DataFrame([], columns=cols, index=samples.index)\n",
    "    for sample_idx, vals in samples.iterrows():\n",
    "        counts, _ = np.histogram(vals, bins=bins, density=True)\n",
    "        res.loc[sample_idx] = pd.Series(counts, index=cols)\n",
    "    return bins, res\n",
    "\n",
    "gal_bins, gal_res = get_sample_hist(gal_pa_samples.T)\n",
    "arm_bins, arm_res = get_sample_hist(arm_pa_samples.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x = np.linspace(0, 90, 1000)\n",
    "plt.figure(figsize=(12, 4), dpi=100)\n",
    "c, b = np.histogram(acot(arm_comparison_dataset), density=True, bins='scott')\n",
    "plt.step(np.concatenate(((0,), b)), np.concatenate(((0,), c, (0,))), where='post', c='k', label='Phi uniform in cot')\n",
    "\n",
    "# plot a histogram with errors of the posterior realizations used to fit things\n",
    "# counts, bins = np.histogram(arm_pa_samples.T.iloc[0], bins='auto', density=True)\n",
    "l_data_gal = plt.errorbar(\n",
    "    gal_res.columns,\n",
    "    gal_res.mean() / sf_gal,\n",
    "    yerr=gal_res.std() / sf_gal,\n",
    "    fmt='.', color='C0',\n",
    "    label='Histogrammed galaxy pitch angle predictions',\n",
    "    zorder=3, capsize=2\n",
    ")\n",
    "plt.step(\n",
    "    np.concatenate(([0], gal_bins)),\n",
    "    np.concatenate(([0], gal_res.mean(), [0])) / sf_gal,\n",
    "    where='post', c='C0', lw=1.5\n",
    ")\n",
    "\n",
    "l_data = plt.errorbar(\n",
    "    arm_res.columns,\n",
    "    arm_res.mean() / sf_arm,\n",
    "    yerr=arm_res.std() / sf_arm,\n",
    "    fmt='.', color='C1',\n",
    "    label='Histogrammed arm pitch angle predictions',\n",
    "    zorder=3, capsize=2\n",
    ")\n",
    "plt.step(\n",
    "    np.concatenate(([0], arm_bins)),\n",
    "    np.concatenate(([0], arm_res.mean(), [0])) / sf_arm,\n",
    "    where='post', c='C1', lw=1.5\n",
    ")\n",
    "\n",
    "# Uncomment to add bin edges\n",
    "# [plt.axvline(b, c='C0', alpha=0.2) for b in gal_bins]\n",
    "# [plt.axvline(b, c='C1', alpha=0.2) for b in arm_bins]\n",
    "\n",
    "plt.axvline(lower_phi_bound_arm, c='k', ls=':', label=r'Lower bound on $\\phi$')\n",
    "plt.axvline(upper_phi_bound_arm, c='k', ls='--', label=r'Upper bound on $\\phi$')\n",
    "plt.legend()\n",
    "plt.xlabel(r'Pitch angle, $\\phi_\\mathrm{gal}$')\n",
    "plt.ylim(0, 0.1)\n",
    "plt.xlim(0, 60)\n",
    "plt.savefig('plots/phi_distribution_comparison.pdf', bbox_inches='tight')\n",
    "plt.savefig('plots/phi_distribution_comparison.jpg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 4))\n",
    "\n",
    "# e_phi_gal = gal_pa_samples.mean(axis=1)\n",
    "# sf_gal = len(e_phi_gal[np.logical_and(e_phi_gal > lower_phi_bound_arm, e_phi_gal < upper_phi_bound_arm)]) / len(e_phi_gal)\n",
    "# c, b = np.histogram(e_phi_gal, density=True, bins='scott')\n",
    "# plt.step(np.concatenate(((0,), b)), np.concatenate(((0,), c, (0,))) / sf_gal, where='post', label=r'$E[\\phi_\\mathrm{gal}]$')\n",
    "\n",
    "# e_phi_arm = arm_pa_samples.mean(axis=1)\n",
    "# sf_arm = len(e_phi_arm[np.logical_and(e_phi_arm > lower_phi_bound_arm, e_phi_arm < upper_phi_bound_arm)]) / len(e_phi_arm)\n",
    "# c, b = np.histogram(e_phi_arm, density=True, bins='scott')\n",
    "# plt.step(np.concatenate(((0,), b)), np.concatenate(((0,), c, (0,))) / sf_arm, where='post', label=r'$E[\\phi_\\mathrm{arm}]$')\n",
    "\n",
    "# c, b = np.histogram(acot(arm_comparison_dataset), density=True, bins='scott')\n",
    "# plt.step(np.concatenate(((0,), b)), np.concatenate(((0,), c, (0,))), where='post', c='k', label='Phi uniform in cot')\n",
    "# plt.legend();\n",
    "\n",
    "# plt.axvline(lower_phi_bound_arm, c='k', ls=':', label=r'Lower bound on $\\phi$')\n",
    "# plt.axvline(upper_phi_bound_arm, c='k', ls='--', label=r'Upper bound on $\\phi$')\n",
    "# plt.legend()\n",
    "# plt.xlabel(r'Pitch angle, $\\phi_\\mathrm{gal}$')\n",
    "# plt.yticks([]);\n",
    "# plt.savefig('plots/phi_distribution_comparison_expectation.pdf', bbox_inches='tight')\n",
    "# plt.savefig('plots/phi_distribution_comparison_expectation.jpg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the results for $\\phi_\\mathrm{gal}$ and $\\phi_\\mathrm{arm}$ on the same plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=1, figsize=(12, 3.4), sharex=True, dpi=100)\n",
    "plt.title('Anderson-Darling test results for posterior samples')\n",
    "sns.kdeplot(anderson['value'], label=r'$\\phi_\\mathrm{gal}$', shade=True)\n",
    "for i, j in zip(\n",
    "    ('25%', '10%', '5%', '2.5%', '1%', '0.5%', '0.1%'),\n",
    "    np.stack(anderson['levels'].values).mean(axis=0)\n",
    "):\n",
    "    plt.axvline(j, color='k', alpha=0.2)\n",
    "    plt.text(j, plt.ylim()[1]*0.9, i)\n",
    "plt.xlabel('Anderson-Darling statistic for $\\phi_\\mathrm{gal}$ being uniform in cot')\n",
    "sns.kdeplot(anderson_arm['value'], c='C1', label=r'$\\phi_\\mathrm{arm}$', shade=True)\n",
    "for i, j in zip(\n",
    "    ('25%', '10%', '5%', '2.5%', '1%', '0.5%', '0.1%'),\n",
    "    np.stack(anderson_arm['levels'].values).mean(axis=0)\n",
    "):\n",
    "    plt.axvline(j, color='k', alpha=0.2, lw=2 if j == '1%' else 1)\n",
    "    plt.text(j, plt.ylim()[1]*0.9, i)\n",
    "plt.xlabel('Anderson-Darling statistic for $\\phi_\\mathrm{arm}$ being uniform in cot')\n",
    "# [a.set_yticks([]) for a in ax];\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/combined_cot_uniform_marginalized_tests.pdf', bbox_inches='tight')\n",
    "plt.savefig('plots/combined_cot_uniform_marginalized_tests.jpg', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
